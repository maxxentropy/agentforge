# Implementation Task: Chunk 3 - Per-Repository Conformance Tracking System

## Overview

Implement the conformance tracking system as specified in `docs/specs/chunk3-conformance/specification.md`. This system persists verification results, tracks violations over time, manages exemptions, and provides CLI commands for conformance operations.

**Read the full specification first:** `docs/specs/chunk3-conformance/specification.md`

---

## Architecture Summary

```
.agentforge/
├── repo.yaml                    # Existing (Chunk 1)
├── conformance_report.yaml      # Current conformance state (NEW)
├── codebase_profile.yaml        # Extracted codebase metadata (NEW)
├── local.yaml                   # Machine-specific overrides (gitignored)
├── violations/                  # Individual violation records (NEW)
│   └── V-{hash}.yaml           # One file per violation
├── exemptions/                  # Approved exemptions (NEW)
│   └── {exemption-id}.yaml     # One file per exemption
└── history/                     # Historical snapshots (NEW)
    └── YYYY-MM-DD.yaml         # One file per day
```

---

## Phase 1: Schema Definitions

Create the following schema files in `schemas/`:

### 1.1 `schemas/conformance_report.schema.yaml`

```yaml
$schema: "http://json-schema.org/draft-07/schema#"
$id: "https://agentforge.dev/schemas/conformance_report.schema.yaml"
title: "Conformance Report"
description: |
  Current conformance state for a repository. Generated by conformance check,
  provides summary view without parsing individual violation files.

type: object
required:
  - schema_version
  - generated_at
  - run_id
  - run_type
  - summary
  - by_severity
  - by_contract
  - contracts_checked
  - files_checked

properties:
  schema_version:
    type: string
    pattern: "^\\d+\\.\\d+$"
    description: "Schema version for migration support"
    examples: ["1.0"]

  generated_at:
    type: string
    format: date-time
    description: "ISO 8601 timestamp of report generation"

  run_id:
    type: string
    format: uuid
    description: "Unique identifier for this verification run"

  run_type:
    type: string
    enum: [full, incremental]
    description: "Whether this was a full or incremental run"

  summary:
    type: object
    required: [total, passed, failed, exempted, stale]
    properties:
      total:
        type: integer
        minimum: 0
        description: "Total checks executed"
      passed:
        type: integer
        minimum: 0
        description: "Checks that passed"
      failed:
        type: integer
        minimum: 0
        description: "Checks that failed (open violations)"
      exempted:
        type: integer
        minimum: 0
        description: "Violations covered by exemptions"
      stale:
        type: integer
        minimum: 0
        description: "Violations not re-checked this run"

  by_severity:
    type: object
    description: "Violation counts by severity level"
    properties:
      blocker:
        type: integer
        minimum: 0
      critical:
        type: integer
        minimum: 0
      major:
        type: integer
        minimum: 0
      minor:
        type: integer
        minimum: 0
      info:
        type: integer
        minimum: 0

  by_contract:
    type: object
    description: "Violation counts by contract ID"
    additionalProperties:
      type: integer
      minimum: 0

  contracts_checked:
    type: array
    items:
      type: string
    description: "List of contract IDs included in this run"

  files_checked:
    type: integer
    minimum: 0
    description: "Count of files analyzed"

  trend:
    type: object
    description: "Comparison with previous run"
    properties:
      passed_delta:
        type: integer
      failed_delta:
        type: integer
      exempted_delta:
        type: integer
      previous_run_id:
        type: string
        format: uuid

additionalProperties: false

examples:
  - schema_version: "1.0"
    generated_at: "2025-01-15T14:30:00Z"
    run_id: "550e8400-e29b-41d4-a716-446655440000"
    run_type: "full"
    summary:
      total: 100
      passed: 85
      failed: 10
      exempted: 5
      stale: 0
    by_severity:
      blocker: 2
      critical: 3
      major: 5
      minor: 0
      info: 0
    by_contract:
      "agentforge": 7
      "security-baseline": 3
    contracts_checked:
      - "agentforge"
      - "security-baseline"
    files_checked: 45
    trend:
      passed_delta: 5
      failed_delta: -3
      exempted_delta: 0
      previous_run_id: "550e8400-e29b-41d4-a716-446655440001"
```

### 1.2 `schemas/violation.schema.yaml`

```yaml
$schema: "http://json-schema.org/draft-07/schema#"
$id: "https://agentforge.dev/schemas/violation.schema.yaml"
title: "Violation Record"
description: |
  Individual violation record. Stored as V-{hash}.yaml in violations/ directory.
  Hash-based ID ensures stable identity across verification runs.

type: object
required:
  - schema_version
  - violation_id
  - contract_id
  - check_id
  - severity
  - file_path
  - message
  - detected_at
  - last_seen_at
  - status

properties:
  schema_version:
    type: string
    pattern: "^\\d+\\.\\d+$"

  violation_id:
    type: string
    pattern: "^V-[a-f0-9]{12}(-\\d+)?$"
    description: "Hash-based unique identifier"
    examples: ["V-a1b2c3d4e5f6", "V-a1b2c3d4e5f6-1"]

  contract_id:
    type: string
    pattern: "^[a-z][a-z0-9_-]*$"
    description: "Reference to the violated contract"

  check_id:
    type: string
    pattern: "^[a-z][a-z0-9_-]*$"
    description: "Specific check within the contract"

  rule_id:
    type: string
    description: "Optional rule identifier for compound checks"

  severity:
    type: string
    enum: [blocker, critical, major, minor, info]
    description: "Canonical severity level"

  file_path:
    type: string
    description: "Relative path to the violating file"

  line_number:
    type: integer
    minimum: 1
    description: "Line number of violation (null for file-level)"

  column_number:
    type: integer
    minimum: 1
    description: "Column number if available"

  message:
    type: string
    minLength: 1
    description: "Human-readable description of the violation"

  fix_hint:
    type: string
    description: "Suggested remediation"

  code_snippet:
    type: string
    maxLength: 500
    description: "Relevant code context (max 5 lines)"

  detected_at:
    type: string
    format: date-time
    description: "ISO 8601 timestamp of first detection"

  last_seen_at:
    type: string
    format: date-time
    description: "ISO 8601 timestamp of most recent detection"

  status:
    type: string
    enum: [open, resolved, exemption_expired, stale]
    description: "Current violation status"

  resolution:
    type: object
    description: "Resolution details if status is 'resolved'"
    properties:
      resolved_at:
        type: string
        format: date-time
      resolved_by:
        type: string
      reason:
        type: string
        minLength: 1

  exemption_id:
    type: string
    description: "Reference to covering exemption if exempted"

  exemption_expired_at:
    type: string
    format: date-time
    description: "When the covering exemption expired"

additionalProperties: false

examples:
  - schema_version: "1.0"
    violation_id: "V-a1b2c3d4e5f6"
    contract_id: "agentforge"
    check_id: "no-print-statements"
    severity: "major"
    file_path: "tools/verification_runner.py"
    line_number: 42
    message: "Debug print statement found"
    fix_hint: "Remove print statement or use logging"
    detected_at: "2025-01-10T10:00:00Z"
    last_seen_at: "2025-01-15T14:30:00Z"
    status: "open"
```

### 1.3 `schemas/exemption.schema.yaml`

```yaml
$schema: "http://json-schema.org/draft-07/schema#"
$id: "https://agentforge.dev/schemas/exemption.schema.yaml"
title: "Exemption"
description: |
  Approved exception to contract checks with justification and optional expiration.
  Supports scoped exemptions by file pattern, check ID, or specific violations.

type: object
required:
  - schema_version
  - id
  - contract_id
  - check_ids
  - reason
  - approved_by
  - approved_date
  - status
  - scope

properties:
  schema_version:
    type: string
    pattern: "^\\d+\\.\\d+$"

  id:
    type: string
    pattern: "^[a-z][a-z0-9_-]*$"
    description: "Unique exemption identifier"
    examples: ["legacy-console-logging", "test-file-docstrings"]

  contract_id:
    type: string
    pattern: "^[a-z][a-z0-9_-]*$"
    description: "Contract being exempted"

  check_ids:
    type: array
    items:
      type: string
    minItems: 1
    description: "Checks exempted (use '*' for all checks in contract)"
    examples: [["no-print-statements"], ["*"]]

  reason:
    type: string
    minLength: 10
    description: "Justification for the exemption"

  approved_by:
    type: string
    description: "Approver (username, email, or 'self' for acknowledged debt)"
    examples: ["jsmith@example.com", "self"]

  approved_date:
    type: string
    format: date
    description: "ISO 8601 date of approval"

  expires:
    type: string
    format: date
    description: "Optional expiration date (end of day)"

  review_date:
    type: string
    format: date
    description: "Optional date to reconsider exemption"

  status:
    type: string
    enum: [active, expired, resolved, under_review]
    description: "Current exemption status"

  scope:
    type: object
    required: [type]
    properties:
      type:
        type: string
        enum: [check_id, file_pattern, violation_id, global]
        description: "Type of scope restriction"
      patterns:
        type: array
        items:
          type: string
        description: "File glob patterns (for file_pattern type)"
        examples: [["tests/**/*.py", "scripts/*.py"]]
      violation_ids:
        type: array
        items:
          type: string
          pattern: "^V-[a-f0-9]{12}(-\\d+)?$"
        description: "Specific violation IDs (for violation_id type)"
      lines:
        type: object
        properties:
          start:
            type: integer
            minimum: 1
          end:
            type: integer
            minimum: 1
        description: "Optional line range restriction"

  notes:
    type: string
    description: "Additional context or tracking information"

additionalProperties: false

examples:
  - schema_version: "1.0"
    id: "legacy-console-logging"
    contract_id: "agentforge"
    check_ids: ["no-print-statements"]
    reason: "Legacy CLI module uses print for user output. Will migrate to rich in Q2."
    approved_by: "tech-lead@example.com"
    approved_date: "2025-01-01"
    expires: "2025-03-31"
    review_date: "2025-03-01"
    status: "active"
    scope:
      type: "file_pattern"
      patterns:
        - "cli/**/*.py"
```

### 1.4 `schemas/history_snapshot.schema.yaml`

```yaml
$schema: "http://json-schema.org/draft-07/schema#"
$id: "https://agentforge.dev/schemas/history_snapshot.schema.yaml"
title: "History Snapshot"
description: |
  Point-in-time summary of conformance state for trend analysis.
  One snapshot per day, contains only aggregate counts.

type: object
required:
  - schema_version
  - date
  - generated_at
  - summary
  - by_severity
  - by_contract
  - files_analyzed
  - contracts_checked

properties:
  schema_version:
    type: string
    pattern: "^\\d+\\.\\d+$"

  date:
    type: string
    format: date
    description: "Snapshot date (YYYY-MM-DD)"

  generated_at:
    type: string
    format: date-time
    description: "Generation timestamp"

  summary:
    type: object
    required: [total, passed, failed, exempted, stale]
    properties:
      total:
        type: integer
        minimum: 0
      passed:
        type: integer
        minimum: 0
      failed:
        type: integer
        minimum: 0
      exempted:
        type: integer
        minimum: 0
      stale:
        type: integer
        minimum: 0

  by_severity:
    type: object
    additionalProperties:
      type: integer
      minimum: 0

  by_contract:
    type: object
    additionalProperties:
      type: integer
      minimum: 0

  files_analyzed:
    type: integer
    minimum: 0

  contracts_checked:
    type: array
    items:
      type: string

additionalProperties: false

examples:
  - schema_version: "1.0"
    date: "2025-01-15"
    generated_at: "2025-01-15T23:59:00Z"
    summary:
      total: 100
      passed: 85
      failed: 10
      exempted: 5
      stale: 0
    by_severity:
      blocker: 2
      critical: 3
      major: 5
    by_contract:
      agentforge: 7
      security-baseline: 3
    files_analyzed: 45
    contracts_checked:
      - agentforge
      - security-baseline
```

### 1.5 `schemas/codebase_profile.schema.yaml`

```yaml
$schema: "http://json-schema.org/draft-07/schema#"
$id: "https://agentforge.dev/schemas/codebase_profile.schema.yaml"
title: "Codebase Profile"
description: |
  Extracted metadata about codebase structure, patterns, and conventions.
  May be auto-detected or manually curated.

type: object
required:
  - schema_version
  - generated_at
  - languages
  - structure

properties:
  schema_version:
    type: string
    pattern: "^\\d+\\.\\d+$"

  generated_at:
    type: string
    format: date-time

  languages:
    type: array
    items:
      type: object
      required: [name, percentage, source]
      properties:
        name:
          type: string
          description: "Language name"
        percentage:
          type: number
          minimum: 0
          maximum: 100
          description: "Percentage of codebase"
        confidence:
          type: number
          minimum: 0
          maximum: 1
          description: "Detection confidence"
        source:
          type: string
          enum: [auto-detected, manual]

  frameworks:
    type: array
    items:
      type: string
    description: "Detected frameworks/libraries"

  structure:
    type: object
    required: [root_path]
    properties:
      root_path:
        type: string
      layers:
        type: array
        items:
          type: object
          properties:
            name:
              type: string
            path:
              type: string
            description:
              type: string
      key_directories:
        type: array
        items:
          type: object
          properties:
            path:
              type: string
            purpose:
              type: string
      entry_points:
        type: array
        items:
          type: string

  patterns_detected:
    type: object
    properties:
      naming_conventions:
        type: object
        additionalProperties:
          type: string
      file_organization:
        type: string

  metrics:
    type: object
    properties:
      total_files:
        type: integer
        minimum: 0
      total_lines:
        type: integer
        minimum: 0
      test_coverage_percent:
        type: number
        minimum: 0
        maximum: 100

additionalProperties: false
```

---

## Phase 2: Domain Layer

Create `tools/conformance/domain.py` with domain entities:

```python
"""
Conformance Domain Entities
===========================

Pure domain objects for conformance tracking. No I/O operations.
"""

from dataclasses import dataclass, field
from datetime import date, datetime
from enum import Enum
from typing import List, Optional, Dict
import hashlib
import fnmatch


class Severity(Enum):
    """Canonical severity levels."""
    BLOCKER = "blocker"
    CRITICAL = "critical"
    MAJOR = "major"
    MINOR = "minor"
    INFO = "info"
    
    @classmethod
    def from_contract_severity(cls, severity: str) -> "Severity":
        """Map contract severity to conformance severity."""
        mapping = {
            "error": cls.BLOCKER,
            "warning": cls.MAJOR,
            "info": cls.MINOR,
        }
        return mapping.get(severity.lower(), cls.MAJOR)


class ViolationStatus(Enum):
    """Possible states for a violation."""
    OPEN = "open"
    RESOLVED = "resolved"
    EXEMPTION_EXPIRED = "exemption_expired"
    STALE = "stale"


class ExemptionStatus(Enum):
    """Possible states for an exemption."""
    ACTIVE = "active"
    EXPIRED = "expired"
    RESOLVED = "resolved"
    UNDER_REVIEW = "under_review"


class ExemptionScopeType(Enum):
    """Types of exemption scope."""
    CHECK_ID = "check_id"
    FILE_PATTERN = "file_pattern"
    VIOLATION_ID = "violation_id"
    GLOBAL = "global"


@dataclass
class ExemptionScope:
    """Defines what violations an exemption covers."""
    type: ExemptionScopeType
    patterns: Optional[List[str]] = None
    violation_ids: Optional[List[str]] = None
    lines: Optional[tuple] = None  # (start, end)
    
    def matches_file(self, file_path: str) -> bool:
        """Check if file path matches scope patterns."""
        if self.type == ExemptionScopeType.GLOBAL:
            return True
        if self.type == ExemptionScopeType.FILE_PATTERN and self.patterns:
            return any(fnmatch.fnmatch(file_path, p) for p in self.patterns)
        return False
    
    def matches_violation_id(self, violation_id: str) -> bool:
        """Check if violation ID matches scope."""
        if self.type == ExemptionScopeType.GLOBAL:
            return True
        if self.type == ExemptionScopeType.VIOLATION_ID and self.violation_ids:
            return violation_id in self.violation_ids
        return False


@dataclass
class Violation:
    """Individual violation record."""
    violation_id: str
    contract_id: str
    check_id: str
    severity: Severity
    file_path: str
    message: str
    detected_at: datetime
    last_seen_at: datetime
    status: ViolationStatus
    line_number: Optional[int] = None
    column_number: Optional[int] = None
    rule_id: Optional[str] = None
    fix_hint: Optional[str] = None
    code_snippet: Optional[str] = None
    resolution: Optional[Dict] = None
    exemption_id: Optional[str] = None
    exemption_expired_at: Optional[datetime] = None
    
    @staticmethod
    def generate_id(
        contract_id: str,
        check_id: str,
        file_path: str,
        line_number: Optional[int],
        rule_id: Optional[str] = None
    ) -> str:
        """Generate deterministic violation ID from composite key."""
        # Normalize file path
        normalized_path = file_path.replace("\\", "/")
        line_str = str(line_number) if line_number else "file"
        rule_str = rule_id or ""
        
        composite = f"{contract_id}|{check_id}|{normalized_path}|{line_str}|{rule_str}"
        hash_digest = hashlib.sha256(composite.encode()).hexdigest()[:12]
        return f"V-{hash_digest}"
    
    def mark_resolved(self, reason: str, resolved_by: str = "system") -> None:
        """Mark violation as resolved."""
        self.status = ViolationStatus.RESOLVED
        self.resolution = {
            "resolved_at": datetime.utcnow().isoformat(),
            "resolved_by": resolved_by,
            "reason": reason,
        }
    
    def mark_stale(self) -> None:
        """Mark violation as stale (not checked in incremental run)."""
        self.status = ViolationStatus.STALE
    
    def mark_exemption_expired(self) -> None:
        """Mark violation as having an expired exemption."""
        self.status = ViolationStatus.EXEMPTION_EXPIRED
        self.exemption_expired_at = datetime.utcnow()


@dataclass
class Exemption:
    """Approved exception to contract checks."""
    id: str
    contract_id: str
    check_ids: List[str]
    reason: str
    approved_by: str
    approved_date: date
    status: ExemptionStatus
    scope: ExemptionScope
    expires: Optional[date] = None
    review_date: Optional[date] = None
    notes: Optional[str] = None
    
    def is_expired(self) -> bool:
        """Check if exemption has expired."""
        if not self.expires:
            return False
        return date.today() > self.expires
    
    def is_active(self) -> bool:
        """Check if exemption is currently active."""
        return self.status == ExemptionStatus.ACTIVE and not self.is_expired()
    
    def covers_check(self, check_id: str) -> bool:
        """Check if this exemption covers a specific check."""
        return "*" in self.check_ids or check_id in self.check_ids
    
    def covers_violation(self, violation: Violation) -> bool:
        """Check if this exemption covers a violation."""
        if violation.contract_id != self.contract_id:
            return False
        if not self.covers_check(violation.check_id):
            return False
        if not self.is_active():
            return False
        
        # Check scope
        if self.scope.type == ExemptionScopeType.GLOBAL:
            return True
        if self.scope.type == ExemptionScopeType.CHECK_ID:
            return True  # Already checked above
        if self.scope.type == ExemptionScopeType.FILE_PATTERN:
            return self.scope.matches_file(violation.file_path)
        if self.scope.type == ExemptionScopeType.VIOLATION_ID:
            return self.scope.matches_violation_id(violation.violation_id)
        
        return False


@dataclass
class ConformanceSummary:
    """Aggregate counts for conformance state."""
    total: int = 0
    passed: int = 0
    failed: int = 0
    exempted: int = 0
    stale: int = 0
    
    def __post_init__(self):
        """Validate invariant."""
        assert self.total >= self.passed + self.failed + self.exempted


@dataclass
class ConformanceReport:
    """Current conformance state for a repository."""
    schema_version: str
    generated_at: datetime
    run_id: str
    run_type: str  # "full" or "incremental"
    summary: ConformanceSummary
    by_severity: Dict[str, int]
    by_contract: Dict[str, int]
    contracts_checked: List[str]
    files_checked: int
    trend: Optional[Dict] = None


@dataclass
class HistorySnapshot:
    """Point-in-time summary for trend analysis."""
    schema_version: str
    date: date
    generated_at: datetime
    summary: ConformanceSummary
    by_severity: Dict[str, int]
    by_contract: Dict[str, int]
    files_analyzed: int
    contracts_checked: List[str]
```

---

## Phase 3: Infrastructure Layer

Create `tools/conformance/stores.py` with storage implementations:

```python
"""
Conformance Storage Infrastructure
==================================

File-based storage for violations, exemptions, and history.
All writes use atomic operations (write to temp, then rename).
"""

import os
import tempfile
import shutil
from pathlib import Path
from typing import List, Optional, Dict, Set
from datetime import date, datetime
import yaml

from .domain import (
    Violation, ViolationStatus, Severity,
    Exemption, ExemptionStatus, ExemptionScope, ExemptionScopeType,
    HistorySnapshot, ConformanceSummary, ConformanceReport
)


class AtomicFileWriter:
    """Context manager for atomic file writes."""
    
    def __init__(self, target_path: Path):
        self.target_path = target_path
        self.temp_path = None
        self.file = None
    
    def __enter__(self):
        self.target_path.parent.mkdir(parents=True, exist_ok=True)
        fd, self.temp_path = tempfile.mkstemp(
            dir=self.target_path.parent,
            suffix=".tmp"
        )
        self.file = os.fdopen(fd, 'w', encoding='utf-8')
        return self.file
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.file.close()
        if exc_type is None:
            # Success - atomically replace target
            shutil.move(self.temp_path, self.target_path)
        else:
            # Error - clean up temp file
            os.unlink(self.temp_path)
        return False


class ViolationStore:
    """Manages violations/ directory."""
    
    def __init__(self, agentforge_path: Path):
        self.violations_path = agentforge_path / "violations"
        self._cache: Dict[str, Violation] = {}
    
    def ensure_directory(self) -> None:
        """Create violations directory if needed."""
        self.violations_path.mkdir(parents=True, exist_ok=True)
        gitkeep = self.violations_path / ".gitkeep"
        if not gitkeep.exists():
            gitkeep.touch()
    
    def load_all(self) -> List[Violation]:
        """Load all violations from disk."""
        self._cache.clear()
        violations = []
        
        if not self.violations_path.exists():
            return violations
        
        for file_path in self.violations_path.glob("V-*.yaml"):
            violation = self._load_violation(file_path)
            if violation:
                self._cache[violation.violation_id] = violation
                violations.append(violation)
        
        return violations
    
    def _load_violation(self, file_path: Path) -> Optional[Violation]:
        """Load a single violation from YAML file."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
            return self._dict_to_violation(data)
        except Exception:
            return None
    
    def _dict_to_violation(self, data: Dict) -> Violation:
        """Convert dictionary to Violation object."""
        return Violation(
            violation_id=data["violation_id"],
            contract_id=data["contract_id"],
            check_id=data["check_id"],
            severity=Severity(data["severity"]),
            file_path=data["file_path"],
            message=data["message"],
            detected_at=datetime.fromisoformat(data["detected_at"]),
            last_seen_at=datetime.fromisoformat(data["last_seen_at"]),
            status=ViolationStatus(data["status"]),
            line_number=data.get("line_number"),
            column_number=data.get("column_number"),
            rule_id=data.get("rule_id"),
            fix_hint=data.get("fix_hint"),
            code_snippet=data.get("code_snippet"),
            resolution=data.get("resolution"),
            exemption_id=data.get("exemption_id"),
            exemption_expired_at=(
                datetime.fromisoformat(data["exemption_expired_at"])
                if data.get("exemption_expired_at") else None
            ),
        )
    
    def _violation_to_dict(self, violation: Violation) -> Dict:
        """Convert Violation object to dictionary for YAML."""
        data = {
            "schema_version": "1.0",
            "violation_id": violation.violation_id,
            "contract_id": violation.contract_id,
            "check_id": violation.check_id,
            "severity": violation.severity.value,
            "file_path": violation.file_path,
            "message": violation.message,
            "detected_at": violation.detected_at.isoformat(),
            "last_seen_at": violation.last_seen_at.isoformat(),
            "status": violation.status.value,
        }
        
        # Optional fields
        if violation.line_number:
            data["line_number"] = violation.line_number
        if violation.column_number:
            data["column_number"] = violation.column_number
        if violation.rule_id:
            data["rule_id"] = violation.rule_id
        if violation.fix_hint:
            data["fix_hint"] = violation.fix_hint
        if violation.code_snippet:
            data["code_snippet"] = violation.code_snippet
        if violation.resolution:
            data["resolution"] = violation.resolution
        if violation.exemption_id:
            data["exemption_id"] = violation.exemption_id
        if violation.exemption_expired_at:
            data["exemption_expired_at"] = violation.exemption_expired_at.isoformat()
        
        return data
    
    def get(self, violation_id: str) -> Optional[Violation]:
        """Get violation by ID."""
        if violation_id in self._cache:
            return self._cache[violation_id]
        
        file_path = self.violations_path / f"{violation_id}.yaml"
        if file_path.exists():
            violation = self._load_violation(file_path)
            if violation:
                self._cache[violation_id] = violation
            return violation
        return None
    
    def save(self, violation: Violation) -> None:
        """Save violation to disk atomically."""
        self.ensure_directory()
        file_path = self.violations_path / f"{violation.violation_id}.yaml"
        data = self._violation_to_dict(violation)
        
        with AtomicFileWriter(file_path) as f:
            yaml.dump(data, f, default_flow_style=False, sort_keys=False)
        
        self._cache[violation.violation_id] = violation
    
    def delete(self, violation_id: str) -> bool:
        """Delete violation file."""
        file_path = self.violations_path / f"{violation_id}.yaml"
        if file_path.exists():
            file_path.unlink()
            self._cache.pop(violation_id, None)
            return True
        return False
    
    def find_by_file(self, file_path: str) -> List[Violation]:
        """Find violations for a specific file."""
        return [v for v in self._cache.values() if v.file_path == file_path]
    
    def find_by_contract(self, contract_id: str) -> List[Violation]:
        """Find violations for a specific contract."""
        return [v for v in self._cache.values() if v.contract_id == contract_id]
    
    def find_by_status(self, status: ViolationStatus) -> List[Violation]:
        """Find violations by status."""
        return [v for v in self._cache.values() if v.status == status]
    
    def mark_stale(
        self,
        except_files: Set[str],
        except_contracts: Set[str]
    ) -> int:
        """Mark violations as stale except for specified scope."""
        count = 0
        for violation in self._cache.values():
            if violation.status != ViolationStatus.OPEN:
                continue
            if violation.file_path in except_files:
                continue
            if violation.contract_id in except_contracts:
                continue
            violation.mark_stale()
            self.save(violation)
            count += 1
        return count


class ExemptionRegistry:
    """Manages exemptions/ directory."""
    
    def __init__(self, agentforge_path: Path):
        self.exemptions_path = agentforge_path / "exemptions"
        self._cache: Dict[str, Exemption] = {}
    
    def ensure_directory(self) -> None:
        """Create exemptions directory if needed."""
        self.exemptions_path.mkdir(parents=True, exist_ok=True)
        gitkeep = self.exemptions_path / ".gitkeep"
        if not gitkeep.exists():
            gitkeep.touch()
    
    def load_all(self) -> List[Exemption]:
        """Load all exemptions from disk."""
        self._cache.clear()
        exemptions = []
        
        if not self.exemptions_path.exists():
            return exemptions
        
        for file_path in self.exemptions_path.glob("*.yaml"):
            if file_path.name == ".gitkeep":
                continue
            exemption = self._load_exemption(file_path)
            if exemption:
                self._cache[exemption.id] = exemption
                exemptions.append(exemption)
        
        return exemptions
    
    def _load_exemption(self, file_path: Path) -> Optional[Exemption]:
        """Load exemption from YAML file."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
            return self._dict_to_exemption(data)
        except Exception:
            return None
    
    def _dict_to_exemption(self, data: Dict) -> Exemption:
        """Convert dictionary to Exemption object."""
        scope_data = data.get("scope", {"type": "global"})
        scope = ExemptionScope(
            type=ExemptionScopeType(scope_data["type"]),
            patterns=scope_data.get("patterns"),
            violation_ids=scope_data.get("violation_ids"),
            lines=(
                (scope_data["lines"]["start"], scope_data["lines"]["end"])
                if scope_data.get("lines") else None
            ),
        )
        
        return Exemption(
            id=data["id"],
            contract_id=data["contract_id"],
            check_ids=data["check_ids"],
            reason=data["reason"],
            approved_by=data["approved_by"],
            approved_date=date.fromisoformat(data["approved_date"]),
            status=ExemptionStatus(data["status"]),
            scope=scope,
            expires=(
                date.fromisoformat(data["expires"])
                if data.get("expires") else None
            ),
            review_date=(
                date.fromisoformat(data["review_date"])
                if data.get("review_date") else None
            ),
            notes=data.get("notes"),
        )
    
    def find_for_violation(self, violation: Violation) -> Optional[Exemption]:
        """Find exemption that covers a violation."""
        for exemption in self._cache.values():
            if exemption.covers_violation(violation):
                return exemption
        return None
    
    def get_expired(self) -> List[Exemption]:
        """Get all expired exemptions."""
        return [e for e in self._cache.values() if e.is_expired()]
    
    def get_active(self) -> List[Exemption]:
        """Get all active exemptions."""
        return [e for e in self._cache.values() if e.is_active()]
    
    def update_status(self, exemption_id: str, status: ExemptionStatus) -> None:
        """Update exemption status and save."""
        if exemption_id in self._cache:
            exemption = self._cache[exemption_id]
            exemption.status = status
            # Save would go here (similar pattern to ViolationStore.save)


class HistoryStore:
    """Manages history/ directory."""
    
    def __init__(self, agentforge_path: Path, retention_days: int = 90):
        self.history_path = agentforge_path / "history"
        self.retention_days = max(7, min(365, retention_days))
    
    def ensure_directory(self) -> None:
        """Create history directory if needed."""
        self.history_path.mkdir(parents=True, exist_ok=True)
        gitkeep = self.history_path / ".gitkeep"
        if not gitkeep.exists():
            gitkeep.touch()
    
    def save_snapshot(self, snapshot: HistorySnapshot) -> None:
        """Save or overwrite daily snapshot."""
        self.ensure_directory()
        file_path = self.history_path / f"{snapshot.date.isoformat()}.yaml"
        
        data = {
            "schema_version": snapshot.schema_version,
            "date": snapshot.date.isoformat(),
            "generated_at": snapshot.generated_at.isoformat(),
            "summary": {
                "total": snapshot.summary.total,
                "passed": snapshot.summary.passed,
                "failed": snapshot.summary.failed,
                "exempted": snapshot.summary.exempted,
                "stale": snapshot.summary.stale,
            },
            "by_severity": snapshot.by_severity,
            "by_contract": snapshot.by_contract,
            "files_analyzed": snapshot.files_analyzed,
            "contracts_checked": snapshot.contracts_checked,
        }
        
        with AtomicFileWriter(file_path) as f:
            yaml.dump(data, f, default_flow_style=False, sort_keys=False)
    
    def get_snapshot(self, snapshot_date: date) -> Optional[HistorySnapshot]:
        """Get snapshot for specific date."""
        file_path = self.history_path / f"{snapshot_date.isoformat()}.yaml"
        if not file_path.exists():
            return None
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
            return self._dict_to_snapshot(data)
        except Exception:
            return None
    
    def _dict_to_snapshot(self, data: Dict) -> HistorySnapshot:
        """Convert dictionary to HistorySnapshot."""
        summary_data = data["summary"]
        return HistorySnapshot(
            schema_version=data["schema_version"],
            date=date.fromisoformat(data["date"]),
            generated_at=datetime.fromisoformat(data["generated_at"]),
            summary=ConformanceSummary(
                total=summary_data["total"],
                passed=summary_data["passed"],
                failed=summary_data["failed"],
                exempted=summary_data["exempted"],
                stale=summary_data.get("stale", 0),
            ),
            by_severity=data["by_severity"],
            by_contract=data["by_contract"],
            files_analyzed=data["files_analyzed"],
            contracts_checked=data["contracts_checked"],
        )
    
    def get_range(
        self,
        start_date: date,
        end_date: date
    ) -> List[HistorySnapshot]:
        """Get snapshots for date range."""
        snapshots = []
        current = start_date
        while current <= end_date:
            snapshot = self.get_snapshot(current)
            if snapshot:
                snapshots.append(snapshot)
            current = date(
                current.year,
                current.month,
                current.day + 1
            ) if current.day < 28 else date(
                current.year + (1 if current.month == 12 else 0),
                (current.month % 12) + 1,
                1
            )
        return snapshots
    
    def prune_old_snapshots(self) -> int:
        """Delete snapshots older than retention period."""
        if not self.history_path.exists():
            return 0
        
        from datetime import timedelta
        cutoff = date.today() - timedelta(days=self.retention_days)
        count = 0
        
        for file_path in self.history_path.glob("*.yaml"):
            if file_path.name == ".gitkeep":
                continue
            try:
                file_date = date.fromisoformat(file_path.stem)
                if file_date < cutoff:
                    file_path.unlink()
                    count += 1
            except ValueError:
                continue
        
        return count
```

---

## Phase 4: Application Layer

Create `tools/conformance/manager.py` with the main orchestration:

```python
"""
Conformance Manager
===================

Application layer orchestration for conformance operations.
Coordinates between verification engine, stores, and CLI.
"""

import uuid
from datetime import date, datetime
from pathlib import Path
from typing import List, Optional, Dict, Set
import yaml

from .domain import (
    Violation, ViolationStatus, Severity,
    Exemption, ExemptionStatus,
    ConformanceReport, ConformanceSummary, HistorySnapshot
)
from .stores import ViolationStore, ExemptionRegistry, HistoryStore, AtomicFileWriter


class ConformanceManager:
    """Orchestrates conformance operations."""
    
    def __init__(self, repo_root: Path):
        self.repo_root = repo_root
        self.agentforge_path = repo_root / ".agentforge"
        
        self.violation_store = ViolationStore(self.agentforge_path)
        self.exemption_registry = ExemptionRegistry(self.agentforge_path)
        self.history_store = HistoryStore(self.agentforge_path)
        
        self._previous_report: Optional[ConformanceReport] = None
    
    def initialize(self, force: bool = False) -> None:
        """Initialize .agentforge/ directory structure."""
        if self.agentforge_path.exists() and not force:
            raise FileExistsError(
                ".agentforge/ already exists. Use --force to reinitialize."
            )
        
        # Create directories
        self.agentforge_path.mkdir(exist_ok=True)
        self.violation_store.ensure_directory()
        self.exemption_registry.ensure_directory()
        self.history_store.ensure_directory()
        
        # Create initial conformance report
        initial_report = ConformanceReport(
            schema_version="1.0",
            generated_at=datetime.utcnow(),
            run_id=str(uuid.uuid4()),
            run_type="full",
            summary=ConformanceSummary(),
            by_severity={},
            by_contract={},
            contracts_checked=[],
            files_checked=0,
        )
        self._save_report(initial_report)
        
        # Add local.yaml to .gitignore
        self._update_gitignore()
    
    def _update_gitignore(self) -> None:
        """Add local.yaml to .gitignore if not present."""
        gitignore_path = self.repo_root / ".gitignore"
        entry = ".agentforge/local.yaml"
        
        if gitignore_path.exists():
            content = gitignore_path.read_text()
            if entry not in content:
                with open(gitignore_path, 'a') as f:
                    f.write(f"\n# AgentForge local config\n{entry}\n")
        else:
            gitignore_path.write_text(f"# AgentForge local config\n{entry}\n")
    
    def run_conformance_check(
        self,
        verification_results: List[Dict],
        contracts_checked: List[str],
        files_checked: int,
        is_full_run: bool = True
    ) -> ConformanceReport:
        """
        Process verification results and update conformance state.
        
        Args:
            verification_results: List of violations from verification engine
            contracts_checked: List of contract IDs that were checked
            files_checked: Number of files analyzed
            is_full_run: Whether this was a full or incremental run
        
        Returns:
            Generated ConformanceReport
        """
        # Load existing state
        self.violation_store.load_all()
        self.exemption_registry.load_all()
        self._previous_report = self._load_report()
        
        # Handle expired exemptions
        self._process_expired_exemptions()
        
        # Track which violations are still present
        seen_violation_ids: Set[str] = set()
        
        # Process new/updated violations
        for result in verification_results:
            violation = self._create_or_update_violation(result)
            seen_violation_ids.add(violation.violation_id)
            
            # Check for exemption
            exemption = self.exemption_registry.find_for_violation(violation)
            if exemption:
                violation.exemption_id = exemption.id
            else:
                violation.exemption_id = None
            
            self.violation_store.save(violation)
        
        # Mark resolved violations (present before, not seen now)
        if is_full_run:
            self._mark_resolved_violations(seen_violation_ids, contracts_checked)
        else:
            # Incremental: mark as stale instead
            self._mark_stale_violations(seen_violation_ids, contracts_checked)
        
        # Generate report
        report = self._generate_report(contracts_checked, files_checked, is_full_run)
        self._save_report(report)
        
        # Save history snapshot
        self._save_history_snapshot(report)
        
        # Prune old history
        self.history_store.prune_old_snapshots()
        
        return report
    
    def _create_or_update_violation(self, result: Dict) -> Violation:
        """Create new violation or update existing one."""
        violation_id = Violation.generate_id(
            contract_id=result["contract_id"],
            check_id=result["check_id"],
            file_path=result["file"],
            line_number=result.get("line"),
            rule_id=result.get("rule_id"),
        )
        
        existing = self.violation_store.get(violation_id)
        now = datetime.utcnow()
        
        if existing:
            # Update last_seen_at and ensure open status
            existing.last_seen_at = now
            if existing.status in (ViolationStatus.RESOLVED, ViolationStatus.STALE):
                existing.status = ViolationStatus.OPEN
            return existing
        
        # Create new violation
        return Violation(
            violation_id=violation_id,
            contract_id=result["contract_id"],
            check_id=result["check_id"],
            severity=Severity.from_contract_severity(result.get("severity", "warning")),
            file_path=result["file"],
            message=result["message"],
            detected_at=now,
            last_seen_at=now,
            status=ViolationStatus.OPEN,
            line_number=result.get("line"),
            fix_hint=result.get("fix_hint"),
        )
    
    def _process_expired_exemptions(self) -> None:
        """Handle expired exemptions and update affected violations."""
        for exemption in self.exemption_registry.get_expired():
            if exemption.status == ExemptionStatus.ACTIVE:
                exemption.status = ExemptionStatus.EXPIRED
                # Find affected violations
                for violation in self.violation_store.find_by_contract(exemption.contract_id):
                    if violation.exemption_id == exemption.id:
                        violation.mark_exemption_expired()
                        self.violation_store.save(violation)
    
    def _mark_resolved_violations(
        self,
        seen_ids: Set[str],
        contracts_checked: List[str]
    ) -> None:
        """Mark violations as resolved if not seen in full run."""
        for violation in self.violation_store.find_by_status(ViolationStatus.OPEN):
            if violation.contract_id not in contracts_checked:
                continue
            if violation.violation_id not in seen_ids:
                violation.mark_resolved("No longer detected in full verification run")
                self.violation_store.save(violation)
    
    def _mark_stale_violations(
        self,
        seen_ids: Set[str],
        contracts_checked: List[str]
    ) -> None:
        """Mark violations as stale if not checked in incremental run."""
        checked_contracts = set(contracts_checked)
        for violation in self.violation_store.find_by_status(ViolationStatus.OPEN):
            if violation.contract_id in checked_contracts:
                if violation.violation_id not in seen_ids:
                    violation.mark_stale()
                    self.violation_store.save(violation)
    
    def _generate_report(
        self,
        contracts_checked: List[str],
        files_checked: int,
        is_full_run: bool
    ) -> ConformanceReport:
        """Generate conformance report from current state."""
        all_violations = self.violation_store.load_all()
        
        # Count by status
        open_violations = [v for v in all_violations if v.status == ViolationStatus.OPEN]
        exempted_violations = [v for v in open_violations if v.exemption_id]
        failed_violations = [v for v in open_violations if not v.exemption_id]
        stale_violations = [v for v in all_violations if v.status == ViolationStatus.STALE]
        
        # Count by severity
        by_severity: Dict[str, int] = {}
        for v in failed_violations:
            severity_name = v.severity.value
            by_severity[severity_name] = by_severity.get(severity_name, 0) + 1
        
        # Count by contract
        by_contract: Dict[str, int] = {}
        for v in failed_violations:
            by_contract[v.contract_id] = by_contract.get(v.contract_id, 0) + 1
        
        summary = ConformanceSummary(
            total=len(open_violations) + len(stale_violations),
            passed=0,  # Would need check count from verification
            failed=len(failed_violations),
            exempted=len(exempted_violations),
            stale=len(stale_violations),
        )
        
        # Calculate trend
        trend = None
        if self._previous_report:
            prev = self._previous_report.summary
            trend = {
                "passed_delta": summary.passed - prev.passed,
                "failed_delta": summary.failed - prev.failed,
                "exempted_delta": summary.exempted - prev.exempted,
                "previous_run_id": self._previous_report.run_id,
            }
        
        return ConformanceReport(
            schema_version="1.0",
            generated_at=datetime.utcnow(),
            run_id=str(uuid.uuid4()),
            run_type="full" if is_full_run else "incremental",
            summary=summary,
            by_severity=by_severity,
            by_contract=by_contract,
            contracts_checked=contracts_checked,
            files_checked=files_checked,
            trend=trend,
        )
    
    def _save_report(self, report: ConformanceReport) -> None:
        """Save conformance report to disk."""
        report_path = self.agentforge_path / "conformance_report.yaml"
        
        data = {
            "schema_version": report.schema_version,
            "generated_at": report.generated_at.isoformat(),
            "run_id": report.run_id,
            "run_type": report.run_type,
            "summary": {
                "total": report.summary.total,
                "passed": report.summary.passed,
                "failed": report.summary.failed,
                "exempted": report.summary.exempted,
                "stale": report.summary.stale,
            },
            "by_severity": report.by_severity,
            "by_contract": report.by_contract,
            "contracts_checked": report.contracts_checked,
            "files_checked": report.files_checked,
        }
        if report.trend:
            data["trend"] = report.trend
        
        with AtomicFileWriter(report_path) as f:
            yaml.dump(data, f, default_flow_style=False, sort_keys=False)
    
    def _load_report(self) -> Optional[ConformanceReport]:
        """Load existing conformance report."""
        report_path = self.agentforge_path / "conformance_report.yaml"
        if not report_path.exists():
            return None
        
        try:
            with open(report_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
            
            summary_data = data["summary"]
            return ConformanceReport(
                schema_version=data["schema_version"],
                generated_at=datetime.fromisoformat(data["generated_at"]),
                run_id=data["run_id"],
                run_type=data["run_type"],
                summary=ConformanceSummary(
                    total=summary_data["total"],
                    passed=summary_data["passed"],
                    failed=summary_data["failed"],
                    exempted=summary_data["exempted"],
                    stale=summary_data.get("stale", 0),
                ),
                by_severity=data["by_severity"],
                by_contract=data["by_contract"],
                contracts_checked=data["contracts_checked"],
                files_checked=data["files_checked"],
                trend=data.get("trend"),
            )
        except Exception:
            return None
    
    def _save_history_snapshot(self, report: ConformanceReport) -> None:
        """Save daily history snapshot."""
        snapshot = HistorySnapshot(
            schema_version="1.0",
            date=date.today(),
            generated_at=datetime.utcnow(),
            summary=report.summary,
            by_severity=report.by_severity,
            by_contract=report.by_contract,
            files_analyzed=report.files_checked,
            contracts_checked=report.contracts_checked,
        )
        self.history_store.save_snapshot(snapshot)
    
    def get_report(self) -> Optional[ConformanceReport]:
        """Get current conformance report."""
        return self._load_report()
    
    def list_violations(
        self,
        status: Optional[ViolationStatus] = None,
        severity: Optional[Severity] = None,
        contract_id: Optional[str] = None,
        file_pattern: Optional[str] = None,
        limit: int = 50
    ) -> List[Violation]:
        """List violations with optional filters."""
        violations = self.violation_store.load_all()
        
        if status:
            violations = [v for v in violations if v.status == status]
        if severity:
            violations = [v for v in violations if v.severity == severity]
        if contract_id:
            violations = [v for v in violations if v.contract_id == contract_id]
        if file_pattern:
            import fnmatch
            violations = [v for v in violations if fnmatch.fnmatch(v.file_path, file_pattern)]
        
        return violations[:limit]
    
    def resolve_violation(self, violation_id: str, reason: str) -> Optional[Violation]:
        """Mark a violation as resolved."""
        violation = self.violation_store.get(violation_id)
        if not violation:
            return None
        
        violation.mark_resolved(reason)
        self.violation_store.save(violation)
        return violation
    
    def prune_violations(self, older_than_days: int = 30, dry_run: bool = False) -> int:
        """Remove old resolved/stale violations."""
        from datetime import timedelta
        cutoff = datetime.utcnow() - timedelta(days=older_than_days)
        
        violations = self.violation_store.load_all()
        to_prune = [
            v for v in violations
            if v.status in (ViolationStatus.RESOLVED, ViolationStatus.STALE)
            and v.last_seen_at < cutoff
        ]
        
        if not dry_run:
            for v in to_prune:
                self.violation_store.delete(v.violation_id)
        
        return len(to_prune)
```

---

## Phase 5: CLI Commands

Add conformance commands to `cli/main.py` (or create `cli/conformance.py`):

```python
"""
Conformance CLI Commands
========================

agentforge conformance init
agentforge conformance check
agentforge conformance report
agentforge conformance violations list|show|resolve|prune
agentforge conformance history
"""

import click
from pathlib import Path

from tools.conformance.manager import ConformanceManager
from tools.conformance.domain import ViolationStatus, Severity


@click.group()
def conformance():
    """Conformance tracking commands."""
    pass


@conformance.command()
@click.option('--force', is_flag=True, help='Overwrite existing conformance files')
@click.pass_context
def init(ctx, force: bool):
    """Initialize conformance tracking for this repository."""
    repo_root = Path.cwd()
    manager = ConformanceManager(repo_root)
    
    try:
        manager.initialize(force=force)
        click.echo("✓ Initialized .agentforge/ conformance tracking")
        click.echo("  Created: violations/, exemptions/, history/")
        click.echo("  Created: conformance_report.yaml")
    except FileExistsError as e:
        click.echo(f"Error: {e}", err=True)
        ctx.exit(1)


@conformance.command()
@click.option('--contracts', multiple=True, help='Specific contracts to check')
@click.option('--files', multiple=True, help='Specific files to check')
@click.option('--full', is_flag=True, help='Run full verification (not incremental)')
@click.option('--no-history', is_flag=True, help='Skip history snapshot')
@click.option('--exit-code', is_flag=True, help='Exit with non-zero on violations')
@click.option('--severity-threshold', default='blocker', 
              type=click.Choice(['blocker', 'critical', 'major', 'minor', 'info']),
              help='Minimum severity for non-zero exit')
@click.pass_context
def check(ctx, contracts, files, full, no_history, exit_code, severity_threshold):
    """Run conformance check and update state."""
    repo_root = Path.cwd()
    manager = ConformanceManager(repo_root)
    
    # TODO: Integrate with verification_runner to get actual results
    # For now, placeholder
    click.echo("Running verification...")
    verification_results = []  # Would come from verification_runner
    contracts_checked = list(contracts) if contracts else ["agentforge"]
    files_checked = len(list(files)) if files else 0
    
    report = manager.run_conformance_check(
        verification_results=verification_results,
        contracts_checked=contracts_checked,
        files_checked=files_checked,
        is_full_run=full or not contracts,
    )
    
    # Display summary
    s = report.summary
    click.echo(f"\n{'='*50}")
    click.echo(f"Conformance Report - {report.generated_at.strftime('%Y-%m-%d %H:%M')}")
    click.echo(f"{'='*50}")
    click.echo(f"  Failed:   {s.failed}")
    click.echo(f"  Exempted: {s.exempted}")
    click.echo(f"  Stale:    {s.stale}")
    
    if report.by_severity:
        click.echo(f"\nBy Severity:")
        for sev, count in sorted(report.by_severity.items()):
            click.echo(f"  {sev}: {count}")
    
    if exit_code:
        threshold_order = ['blocker', 'critical', 'major', 'minor', 'info']
        threshold_idx = threshold_order.index(severity_threshold)
        
        for sev in threshold_order[:threshold_idx + 1]:
            if report.by_severity.get(sev, 0) > 0:
                ctx.exit(1)


@conformance.command()
@click.option('--format', 'fmt', default='text', 
              type=click.Choice(['text', 'json', 'yaml']),
              help='Output format')
@click.option('--verbose', is_flag=True, help='Include violation details')
@click.option('--by-severity', is_flag=True, help='Group by severity')
@click.option('--by-contract', is_flag=True, help='Group by contract')
def report(fmt, verbose, by_severity, by_contract):
    """Display current conformance state."""
    repo_root = Path.cwd()
    manager = ConformanceManager(repo_root)
    
    report = manager.get_report()
    if not report:
        click.echo("No conformance report found. Run 'agentforge conformance check' first.")
        return
    
    if fmt == 'json':
        import json
        click.echo(json.dumps(_report_to_dict(report), indent=2))
    elif fmt == 'yaml':
        import yaml
        click.echo(yaml.dump(_report_to_dict(report), default_flow_style=False))
    else:
        _print_text_report(report, verbose, by_severity, by_contract)


@conformance.group()
def violations():
    """Manage violations."""
    pass


@violations.command('list')
@click.option('--status', type=click.Choice(['open', 'resolved', 'stale', 'exemption_expired']))
@click.option('--severity', type=click.Choice(['blocker', 'critical', 'major', 'minor', 'info']))
@click.option('--contract', help='Filter by contract ID')
@click.option('--file', 'file_pattern', help='Filter by file pattern')
@click.option('--limit', default=50, help='Limit results')
def violations_list(status, severity, contract, file_pattern, limit):
    """List violations."""
    repo_root = Path.cwd()
    manager = ConformanceManager(repo_root)
    
    status_enum = ViolationStatus(status) if status else None
    severity_enum = Severity(severity) if severity else None
    
    violations = manager.list_violations(
        status=status_enum,
        severity=severity_enum,
        contract_id=contract,
        file_pattern=file_pattern,
        limit=limit,
    )
    
    if not violations:
        click.echo("No violations found.")
        return
    
    for v in violations:
        line_info = f":{v.line_number}" if v.line_number else ""
        click.echo(f"{v.violation_id} [{v.severity.value}] {v.file_path}{line_info}")
        click.echo(f"  {v.message}")


@violations.command('show')
@click.argument('violation_id')
def violations_show(violation_id):
    """Show detailed violation record."""
    repo_root = Path.cwd()
    manager = ConformanceManager(repo_root)
    manager.violation_store.load_all()
    
    violation = manager.violation_store.get(violation_id)
    if not violation:
        click.echo(f"Violation {violation_id} not found.", err=True)
        return
    
    click.echo(f"Violation: {violation.violation_id}")
    click.echo(f"  Contract: {violation.contract_id}")
    click.echo(f"  Check: {violation.check_id}")
    click.echo(f"  Severity: {violation.severity.value}")
    click.echo(f"  Status: {violation.status.value}")
    click.echo(f"  File: {violation.file_path}:{violation.line_number or 'file'}")
    click.echo(f"  Message: {violation.message}")
    if violation.fix_hint:
        click.echo(f"  Fix: {violation.fix_hint}")
    click.echo(f"  Detected: {violation.detected_at}")
    click.echo(f"  Last Seen: {violation.last_seen_at}")


@violations.command('resolve')
@click.argument('violation_id')
@click.option('--reason', required=True, help='Resolution reason')
def violations_resolve(violation_id, reason):
    """Mark violation as resolved."""
    repo_root = Path.cwd()
    manager = ConformanceManager(repo_root)
    manager.violation_store.load_all()
    
    violation = manager.resolve_violation(violation_id, reason)
    if violation:
        click.echo(f"✓ Resolved {violation_id}")
    else:
        click.echo(f"Violation {violation_id} not found.", err=True)


@violations.command('prune')
@click.option('--older-than', default=30, help='Prune violations older than N days')
@click.option('--dry-run', is_flag=True, help='Show what would be pruned')
def violations_prune(older_than, dry_run):
    """Remove old resolved/stale violations."""
    repo_root = Path.cwd()
    manager = ConformanceManager(repo_root)
    
    count = manager.prune_violations(older_than_days=older_than, dry_run=dry_run)
    
    if dry_run:
        click.echo(f"Would prune {count} violations")
    else:
        click.echo(f"Pruned {count} violations")


@conformance.command()
@click.option('--days', default=30, help='Show last N days')
@click.option('--format', 'fmt', default='text',
              type=click.Choice(['text', 'json', 'yaml', 'csv']))
@click.option('--metric', default='failed',
              type=click.Choice(['total', 'failed', 'passed', 'exempted']))
def history(days, fmt, metric):
    """Display conformance trend over time."""
    from datetime import date, timedelta
    
    repo_root = Path.cwd()
    manager = ConformanceManager(repo_root)
    
    end_date = date.today()
    start_date = end_date - timedelta(days=days)
    
    snapshots = manager.history_store.get_range(start_date, end_date)
    
    if not snapshots:
        click.echo("No history data found.")
        return
    
    if fmt == 'csv':
        click.echo("date,total,passed,failed,exempted,stale")
        for s in snapshots:
            click.echo(f"{s.date},{s.summary.total},{s.summary.passed},{s.summary.failed},{s.summary.exempted},{s.summary.stale}")
    elif fmt == 'text':
        click.echo(f"Conformance History (last {days} days)")
        click.echo("-" * 40)
        for s in snapshots:
            value = getattr(s.summary, metric)
            click.echo(f"{s.date}: {metric}={value}")


def _report_to_dict(report) -> dict:
    """Convert report to dictionary."""
    return {
        "schema_version": report.schema_version,
        "generated_at": report.generated_at.isoformat(),
        "run_id": report.run_id,
        "run_type": report.run_type,
        "summary": {
            "total": report.summary.total,
            "passed": report.summary.passed,
            "failed": report.summary.failed,
            "exempted": report.summary.exempted,
            "stale": report.summary.stale,
        },
        "by_severity": report.by_severity,
        "by_contract": report.by_contract,
    }


def _print_text_report(report, verbose, by_severity, by_contract):
    """Print text format report."""
    s = report.summary
    click.echo(f"Conformance Report")
    click.echo(f"Generated: {report.generated_at}")
    click.echo(f"Run Type: {report.run_type}")
    click.echo()
    click.echo(f"Summary:")
    click.echo(f"  Total:    {s.total}")
    click.echo(f"  Passed:   {s.passed}")
    click.echo(f"  Failed:   {s.failed}")
    click.echo(f"  Exempted: {s.exempted}")
    click.echo(f"  Stale:    {s.stale}")
    
    if by_severity and report.by_severity:
        click.echo(f"\nBy Severity:")
        for sev, count in sorted(report.by_severity.items()):
            click.echo(f"  {sev}: {count}")
    
    if by_contract and report.by_contract:
        click.echo(f"\nBy Contract:")
        for contract, count in sorted(report.by_contract.items()):
            click.echo(f"  {contract}: {count}")


# Register with main CLI
def register_commands(cli):
    """Register conformance commands with main CLI."""
    cli.add_command(conformance)
```

---

## Phase 6: Integration with Verification Engine

Update `tools/verification_runner.py` to output results in conformance-compatible format:

```python
# Add method to VerificationRunner class:

def get_conformance_results(self) -> List[Dict]:
    """
    Get verification results in conformance-compatible format.
    
    Returns:
        List of violation dictionaries with keys:
        - contract_id: str
        - check_id: str
        - severity: str
        - file: str
        - line: int (optional)
        - message: str
        - fix_hint: str (optional)
        - rule_id: str (optional)
    """
    results = []
    for violation in self.violations:
        results.append({
            "contract_id": violation.get("contract_id", "unknown"),
            "check_id": violation.get("check_id", "unknown"),
            "severity": violation.get("severity", "warning"),
            "file": violation.get("file", ""),
            "line": violation.get("line"),
            "message": violation.get("message", ""),
            "fix_hint": violation.get("fix_hint"),
            "rule_id": violation.get("rule_id"),
        })
    return results
```

---

## Phase 7: Tests

Create `tests/unit/tools/test_conformance/`:

### `test_domain.py`
```python
"""Tests for conformance domain entities."""

import pytest
from datetime import date, datetime
from tools.conformance.domain import (
    Violation, ViolationStatus, Severity,
    Exemption, ExemptionStatus, ExemptionScope, ExemptionScopeType,
    ConformanceSummary,
)


class TestViolation:
    def test_generate_id_deterministic(self):
        """Same inputs should produce same ID."""
        id1 = Violation.generate_id("contract", "check", "file.py", 42, None)
        id2 = Violation.generate_id("contract", "check", "file.py", 42, None)
        assert id1 == id2
    
    def test_generate_id_format(self):
        """ID should match V-{12 hex chars} format."""
        vid = Violation.generate_id("contract", "check", "file.py", 42, None)
        assert vid.startswith("V-")
        assert len(vid) == 14  # V- + 12 chars
    
    def test_mark_resolved(self):
        """Should update status and add resolution."""
        v = Violation(
            violation_id="V-test123",
            contract_id="test",
            check_id="check",
            severity=Severity.MAJOR,
            file_path="test.py",
            message="Test",
            detected_at=datetime.utcnow(),
            last_seen_at=datetime.utcnow(),
            status=ViolationStatus.OPEN,
        )
        v.mark_resolved("Fixed in PR#123")
        assert v.status == ViolationStatus.RESOLVED
        assert v.resolution["reason"] == "Fixed in PR#123"


class TestExemption:
    def test_is_expired_no_expiry(self):
        """Exemption without expiry should not be expired."""
        e = Exemption(
            id="test",
            contract_id="test",
            check_ids=["*"],
            reason="Test exemption",
            approved_by="self",
            approved_date=date.today(),
            status=ExemptionStatus.ACTIVE,
            scope=ExemptionScope(type=ExemptionScopeType.GLOBAL),
        )
        assert not e.is_expired()
    
    def test_covers_violation_global_scope(self):
        """Global scope should cover any violation in contract."""
        e = Exemption(
            id="test",
            contract_id="mycontract",
            check_ids=["*"],
            reason="Test",
            approved_by="self",
            approved_date=date.today(),
            status=ExemptionStatus.ACTIVE,
            scope=ExemptionScope(type=ExemptionScopeType.GLOBAL),
        )
        v = Violation(
            violation_id="V-test123",
            contract_id="mycontract",
            check_id="any-check",
            severity=Severity.MAJOR,
            file_path="any/file.py",
            message="Test",
            detected_at=datetime.utcnow(),
            last_seen_at=datetime.utcnow(),
            status=ViolationStatus.OPEN,
        )
        assert e.covers_violation(v)
    
    def test_covers_violation_file_pattern(self):
        """File pattern scope should match correctly."""
        e = Exemption(
            id="test",
            contract_id="mycontract",
            check_ids=["*"],
            reason="Test",
            approved_by="self",
            approved_date=date.today(),
            status=ExemptionStatus.ACTIVE,
            scope=ExemptionScope(
                type=ExemptionScopeType.FILE_PATTERN,
                patterns=["tests/**/*.py"],
            ),
        )
        v1 = Violation(
            violation_id="V-test1",
            contract_id="mycontract",
            check_id="check",
            severity=Severity.MAJOR,
            file_path="tests/unit/test_foo.py",
            message="Test",
            detected_at=datetime.utcnow(),
            last_seen_at=datetime.utcnow(),
            status=ViolationStatus.OPEN,
        )
        v2 = Violation(
            violation_id="V-test2",
            contract_id="mycontract",
            check_id="check",
            severity=Severity.MAJOR,
            file_path="src/main.py",
            message="Test",
            detected_at=datetime.utcnow(),
            last_seen_at=datetime.utcnow(),
            status=ViolationStatus.OPEN,
        )
        assert e.covers_violation(v1)
        assert not e.covers_violation(v2)
```

### `test_stores.py`
```python
"""Tests for conformance storage infrastructure."""

import pytest
from pathlib import Path
from datetime import date, datetime
from tools.conformance.stores import ViolationStore, HistoryStore
from tools.conformance.domain import Violation, ViolationStatus, Severity, HistorySnapshot, ConformanceSummary


class TestViolationStore:
    def test_save_and_load(self, tmp_path: Path):
        """Should save and load violation correctly."""
        store = ViolationStore(tmp_path)
        store.ensure_directory()
        
        v = Violation(
            violation_id="V-abc123def456",
            contract_id="test",
            check_id="check",
            severity=Severity.MAJOR,
            file_path="test.py",
            line_number=42,
            message="Test violation",
            detected_at=datetime(2025, 1, 15, 10, 0, 0),
            last_seen_at=datetime(2025, 1, 15, 14, 0, 0),
            status=ViolationStatus.OPEN,
        )
        
        store.save(v)
        
        loaded = store.get("V-abc123def456")
        assert loaded is not None
        assert loaded.violation_id == v.violation_id
        assert loaded.message == v.message
        assert loaded.severity == Severity.MAJOR
    
    def test_find_by_contract(self, tmp_path: Path):
        """Should find violations by contract."""
        store = ViolationStore(tmp_path)
        store.ensure_directory()
        
        v1 = Violation(
            violation_id="V-111111111111",
            contract_id="contract-a",
            check_id="check",
            severity=Severity.MAJOR,
            file_path="a.py",
            message="Test",
            detected_at=datetime.utcnow(),
            last_seen_at=datetime.utcnow(),
            status=ViolationStatus.OPEN,
        )
        v2 = Violation(
            violation_id="V-222222222222",
            contract_id="contract-b",
            check_id="check",
            severity=Severity.MAJOR,
            file_path="b.py",
            message="Test",
            detected_at=datetime.utcnow(),
            last_seen_at=datetime.utcnow(),
            status=ViolationStatus.OPEN,
        )
        
        store.save(v1)
        store.save(v2)
        store.load_all()
        
        results = store.find_by_contract("contract-a")
        assert len(results) == 1
        assert results[0].violation_id == "V-111111111111"


class TestHistoryStore:
    def test_save_and_get_snapshot(self, tmp_path: Path):
        """Should save and retrieve daily snapshot."""
        store = HistoryStore(tmp_path)
        store.ensure_directory()
        
        snapshot = HistorySnapshot(
            schema_version="1.0",
            date=date(2025, 1, 15),
            generated_at=datetime(2025, 1, 15, 23, 59, 0),
            summary=ConformanceSummary(total=100, passed=85, failed=10, exempted=5, stale=0),
            by_severity={"major": 10},
            by_contract={"test": 10},
            files_analyzed=45,
            contracts_checked=["test"],
        )
        
        store.save_snapshot(snapshot)
        
        loaded = store.get_snapshot(date(2025, 1, 15))
        assert loaded is not None
        assert loaded.summary.failed == 10
```

### `test_manager.py`
```python
"""Tests for ConformanceManager."""

import pytest
from pathlib import Path
from tools.conformance.manager import ConformanceManager


class TestConformanceManager:
    def test_initialize(self, tmp_path: Path):
        """Should create directory structure."""
        manager = ConformanceManager(tmp_path)
        manager.initialize()
        
        assert (tmp_path / ".agentforge").exists()
        assert (tmp_path / ".agentforge" / "violations").exists()
        assert (tmp_path / ".agentforge" / "exemptions").exists()
        assert (tmp_path / ".agentforge" / "history").exists()
        assert (tmp_path / ".agentforge" / "conformance_report.yaml").exists()
    
    def test_initialize_already_exists(self, tmp_path: Path):
        """Should raise error if already exists."""
        manager = ConformanceManager(tmp_path)
        manager.initialize()
        
        with pytest.raises(FileExistsError):
            manager.initialize(force=False)
    
    def test_run_conformance_check(self, tmp_path: Path):
        """Should process results and generate report."""
        manager = ConformanceManager(tmp_path)
        manager.initialize()
        
        results = [
            {
                "contract_id": "test",
                "check_id": "no-print",
                "severity": "warning",
                "file": "main.py",
                "line": 42,
                "message": "Print statement found",
            }
        ]
        
        report = manager.run_conformance_check(
            verification_results=results,
            contracts_checked=["test"],
            files_checked=10,
            is_full_run=True,
        )
        
        assert report.summary.failed == 1
        assert "test" in report.by_contract
```

---

## Acceptance Criteria

### Functional Requirements

- [ ] `agentforge conformance init` creates .agentforge/ structure
- [ ] `agentforge conformance check` processes verification results
- [ ] Violations are stored with deterministic IDs
- [ ] Exemptions correctly cover violations by scope
- [ ] Expired exemptions surface as exemption_expired violations
- [ ] History snapshots created daily with retention policy
- [ ] Incremental runs mark unchecked violations as stale
- [ ] Full runs mark missing violations as resolved

### Quality Requirements

- [ ] All domain entities have type hints
- [ ] Atomic file operations prevent corruption
- [ ] Unit tests cover domain, stores, and manager
- [ ] CLI commands have --help documentation

### Verification

```bash
# Run tests
python -m pytest tests/unit/tools/test_conformance/ -v

# Test CLI commands
agentforge conformance init
agentforge conformance check --full
agentforge conformance report
agentforge conformance violations list
agentforge conformance history --days 7

# Verify schema validation
python -c "
import yaml
from jsonschema import validate
schema = yaml.safe_load(open('schemas/violation.schema.yaml'))
# Test against example
"
```

---

## Files to Create

| File | Purpose |
|------|---------|
| `schemas/conformance_report.schema.yaml` | Report schema |
| `schemas/violation.schema.yaml` | Violation schema |
| `schemas/exemption.schema.yaml` | Exemption schema |
| `schemas/history_snapshot.schema.yaml` | History schema |
| `schemas/codebase_profile.schema.yaml` | Profile schema |
| `tools/conformance/__init__.py` | Package init |
| `tools/conformance/domain.py` | Domain entities |
| `tools/conformance/stores.py` | Storage infrastructure |
| `tools/conformance/manager.py` | Application orchestration |
| `cli/conformance.py` | CLI commands |
| `tests/unit/tools/test_conformance/test_domain.py` | Domain tests |
| `tests/unit/tools/test_conformance/test_stores.py` | Store tests |
| `tests/unit/tools/test_conformance/test_manager.py` | Manager tests |

---

## References

- Full specification: `docs/specs/chunk3-conformance/specification.md`
- Validation report: `docs/specs/chunk3-conformance/validation_report.yaml`
- Existing patterns: `tools/builtin_checks.py`, `tools/contracts_registry.py`
